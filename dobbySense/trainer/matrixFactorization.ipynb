{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a625e34f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a625e34f",
    "outputId": "844680fc-0d5f-4250-b206-5eb13f8c84c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/48.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/48.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# --- Install Dependencies (run this cell first in Colab) ---\n",
    "!pip install -q supabase gcsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05524b4a",
   "metadata": {
    "id": "05524b4a"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION - All hyperparameters and hardcoded variables\n",
    "# ============================================================\n",
    "\n",
    "# --- Data Paths ---\n",
    "RATINGS_PATH = \"gs://kanta7/ratings.csv\"\n",
    "MOVIES_PATH = \"gs://kanta7/movies.csv\"\n",
    "\n",
    "# --- Supabase Configuration ---\n",
    "SUPABASE_URL = \"https://mgagzgashuexrnkoqkzy.supabase.co\"\n",
    "SUPABASE_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im1nYWd6Z2FzaHVleHJua29xa3p5Iiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1OTkwOTM5NSwiZXhwIjoyMDc1NDg1Mzk1fQ.0klXZZv3b31usiUKTQxyfXsFPLr5TLPDikUY6s3wrPo\"\n",
    "\n",
    "# --- Supabase Table Names ---\n",
    "RATINGS_TABLE = \"movie_ratings\"\n",
    "MOVIE_EMBEDDINGS_TABLE = \"movie_embeddings\"\n",
    "USER_EMBEDDINGS_TABLE = \"user_embeddings\"\n",
    "GENRE_LAYERS_TABLE = \"genre_layers\"\n",
    "\n",
    "# --- Data Processing ---\n",
    "# Use 0.0 to train on ALL data (no validation)\n",
    "TEST_SIZE = 0.0\n",
    "RANDOM_STATE = 42\n",
    "GENRE_COLUMN_PREFIX = \"g\"\n",
    "\n",
    "# --- DataLoader Settings ---\n",
    "BATCH_SIZE = 2048\n",
    "NUM_WORKERS = 2\n",
    "PIN_MEMORY = True\n",
    "\n",
    "# --- Model Hyperparameters ---\n",
    "N_FACTORS = 64\n",
    "MODEL_DROPOUT = 0.1\n",
    "EMBEDDING_INIT_STD = 0.01\n",
    "GENRE_WEIGHT = 0.5  # Weight for genre influence on movie embeddings (reduce to lower genre impact)\n",
    "\n",
    "# --- Training Hyperparameters ---\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-6\n",
    "CLIP_GRAD_NORM = None  # Set to a float value to enable gradient clipping\n",
    "\n",
    "# --- Export Settings ---\n",
    "CHUNK_SIZE = 500  # For batch inserts to Supabase\n",
    "GENRE_LAYER_NAME = \"hybrid_mf_v1\"  # Name for the genre layer export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a90394",
   "metadata": {
    "id": "f5a90394"
   },
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from supabase import create_client, Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0e5797",
   "metadata": {
    "id": "0c0e5797"
   },
   "outputs": [],
   "source": [
    "# --- Google Cloud Authentication (required for GCS bucket access) ---\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0300e7",
   "metadata": {
    "id": "bd0300e7"
   },
   "outputs": [],
   "source": [
    "# ---------- Dataset ----------\n",
    "class RatingsDataset(Dataset):\n",
    "    def __init__(self, user_idx, movie_idx, ratings, genre_matrix):\n",
    "        assert len(user_idx) == len(movie_idx) == len(ratings)\n",
    "        self.users = torch.tensor(user_idx, dtype=torch.long)\n",
    "        self.movies = torch.tensor(movie_idx, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(ratings, dtype=torch.float32)\n",
    "        self.genres = torch.tensor(genre_matrix, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.movies[idx], self.ratings[idx], self.genres[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d66e50",
   "metadata": {
    "id": "f7d66e50"
   },
   "outputs": [],
   "source": [
    "# ---------- Utilities ----------\n",
    "def build_id_maps(df: pd.DataFrame, user_col='userId', movie_col='movieId'):\n",
    "    unique_users = df[user_col].unique()\n",
    "    unique_movies = df[movie_col].unique()\n",
    "    user2idx = {u: i for i, u in enumerate(np.sort(unique_users))}\n",
    "    movie2idx = {m: j for j, m in enumerate(np.sort(unique_movies))}\n",
    "    user_idx = df[user_col].map(user2idx).to_numpy()\n",
    "    movie_idx = df[movie_col].map(movie2idx).to_numpy()\n",
    "    ratings = df['rating'].to_numpy(dtype=np.float32)\n",
    "    return user2idx, movie2idx, user_idx, movie_idx, ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5def99",
   "metadata": {
    "id": "5e5def99"
   },
   "outputs": [],
   "source": [
    "# ---------- Model ----------\n",
    "class HybridMatrixFactorization(nn.Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors, n_genres, dropout=0.0, genre_weight=1.0):\n",
    "        super().__init__()\n",
    "        self.user_factors = nn.Embedding(n_users, n_factors)\n",
    "        self.movie_factors = nn.Embedding(n_movies, n_factors)\n",
    "        self.genre_layer = nn.Linear(n_genres, n_factors)\n",
    "        self.user_bias = nn.Embedding(n_users, 1)\n",
    "        self.movie_bias = nn.Embedding(n_movies, 1)\n",
    "        self.global_bias = nn.Parameter(torch.tensor([0.0]))\n",
    "        self.dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()\n",
    "        self.genre_weight = genre_weight\n",
    "\n",
    "        nn.init.normal_(self.user_factors.weight, std=EMBEDDING_INIT_STD)\n",
    "        nn.init.normal_(self.movie_factors.weight, std=EMBEDDING_INIT_STD)\n",
    "        nn.init.constant_(self.user_bias.weight, 0.0)\n",
    "        nn.init.constant_(self.movie_bias.weight, 0.0)\n",
    "\n",
    "    def forward(self, user, movie, genre_vec):\n",
    "        pu = self.user_factors(user)\n",
    "        qi = self.movie_factors(movie)\n",
    "        genre_emb = self.genre_layer(genre_vec)\n",
    "        qi = qi + self.genre_weight * genre_emb\n",
    "        pu = self.dropout(pu)\n",
    "        qi = self.dropout(qi)\n",
    "        dot = (pu * qi).sum(dim=1)\n",
    "        b_u = self.user_bias(user).squeeze(1)\n",
    "        b_i = self.movie_bias(movie).squeeze(1)\n",
    "        return dot + b_u + b_i + self.global_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c440c33",
   "metadata": {
    "id": "9c440c33"
   },
   "outputs": [],
   "source": [
    "# ---------- Training / Evaluation ----------\n",
    "def rmse(preds, targets):\n",
    "    return math.sqrt(((preds - targets) ** 2).mean().item())\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    ys, y_preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for u, m, r, g in dataloader:\n",
    "            u, m, r, g = u.to(device), m.to(device), r.to(device), g.to(device)\n",
    "            p = model(u, m, g)\n",
    "            ys.append(r.cpu())\n",
    "            y_preds.append(p.cpu())\n",
    "    y = torch.cat(ys)\n",
    "    yp = torch.cat(y_preds)\n",
    "    return rmse(yp, y)\n",
    "\n",
    "def train_fn(model, train_loader, val_loader, device,\n",
    "             epochs=EPOCHS, lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY, clip_grad=CLIP_GRAD_NORM):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss()\n",
    "    best_metric = float('inf')\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss, cnt = 0.0, 0\n",
    "        for u, m, r, g in train_loader:\n",
    "            u, m, r, g = u.to(device), m.to(device), r.to(device), g.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(u, m, g)\n",
    "            loss = criterion(preds, r)\n",
    "            loss.backward()\n",
    "            if clip_grad:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * r.size(0)\n",
    "            cnt += r.size(0)\n",
    "\n",
    "        train_rmse = math.sqrt(total_loss / cnt)\n",
    "        \n",
    "        if val_loader:\n",
    "            val_rmse = evaluate(model, val_loader, device)\n",
    "            print(f\"Epoch {epoch:03d} | train_rmse={train_rmse:.4f} | val_rmse={val_rmse:.4f}\")\n",
    "            metric = val_rmse\n",
    "        else:\n",
    "            print(f\"Epoch {epoch:03d} | train_rmse={train_rmse:.4f}\")\n",
    "            metric = train_rmse\n",
    "\n",
    "        if metric < best_metric:\n",
    "            best_metric = metric\n",
    "\n",
    "    return best_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b648648",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7b648648",
    "outputId": "e1b6512f-81fa-49af-8b7e-65de738047f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 23585151 ratings and 62805 movies with 19 genres\n"
     ]
    }
   ],
   "source": [
    "# ---------- Load Data ----------\n",
    "df = pd.read_csv(RATINGS_PATH)\n",
    "movies_df = pd.read_csv(MOVIES_PATH)\n",
    "\n",
    "df[\"userId\"] = df[\"userId\"].astype(str)\n",
    "movies_df[\"movieId\"] = movies_df[\"movieId\"].astype(int)\n",
    "genre_cols = [c for c in movies_df.columns if c.startswith(GENRE_COLUMN_PREFIX)]\n",
    "n_genres = len(genre_cols)\n",
    "\n",
    "print(f\"Loaded {len(df)} ratings and {len(movies_df)} movies with {n_genres} genres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd5c73d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bd5c73d",
    "outputId": "18a04c2c-83ed-43a0-b885-0142d6a0902b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After merging Supabase data: 23585154 total ratings\n"
     ]
    }
   ],
   "source": [
    "# --- Supabase Connection ---\n",
    "supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
    "\n",
    "# Fetch extra ratings from Supabase\n",
    "response = supabase.table(RATINGS_TABLE).select(\"user_id, movie_id, rating\").execute()\n",
    "df_supabase = pd.DataFrame(response.data).rename(columns={\n",
    "    \"user_id\": \"userId\", \"movie_id\": \"movieId\", \"rating\": \"rating\"\n",
    "})\n",
    "df = pd.concat([df, df_supabase], ignore_index=True)\n",
    "\n",
    "print(f\"After merging Supabase data: {len(df)} total ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee394e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dee394e2",
    "outputId": "89a01d09-7030-44c8-b457-6e35c0e58225"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 324487 users, 61191 movies, 19 genres\n"
     ]
    }
   ],
   "source": [
    "# ---------- Prepare Data ----------\n",
    "if TEST_SIZE > 0:\n",
    "    train_df, val_df = train_test_split(df, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "else:\n",
    "    train_df = df\n",
    "    val_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "user2idx, movie2idx, train_u, train_m, train_r = build_id_maps(train_df)\n",
    "\n",
    "if not val_df.empty:\n",
    "    # Filter validation set to known users/movies\n",
    "    val_df = val_df[val_df['userId'].isin(user2idx) & val_df['movieId'].isin(movie2idx)]\n",
    "    val_u = val_df['userId'].map(user2idx).to_numpy()\n",
    "    val_m = val_df['movieId'].map(movie2idx).to_numpy()\n",
    "    val_r = val_df['rating'].to_numpy(dtype=np.float32)\n",
    "else:\n",
    "    val_u = val_m = val_r = np.array([], dtype=np.float32)\n",
    "\n",
    "# Build genre matrix aligned with movie indices\n",
    "genre_matrix = np.zeros((len(movie2idx), n_genres), dtype=np.float32)\n",
    "for _, row in movies_df.iterrows():\n",
    "    mid = row['movieId']\n",
    "    if mid in movie2idx:\n",
    "        genre_matrix[movie2idx[mid]] = row[genre_cols].values.astype(np.float32)\n",
    "\n",
    "train_genres = genre_matrix[train_m]\n",
    "val_genres = genre_matrix[val_m] if len(val_m) > 0 else np.zeros((0, n_genres))\n",
    "\n",
    "num_users, num_movies = len(user2idx), len(movie2idx)\n",
    "print(f\"Training {num_users} users, {num_movies} movies, {n_genres} genres\")\n",
    "if TEST_SIZE > 0:\n",
    "    print(f\"Validation size: {len(val_df)}\")\n",
    "else:\n",
    "    print(\"Using FULL dataset for training (no validation).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5583905",
   "metadata": {
    "id": "f5583905"
   },
   "outputs": [],
   "source": [
    "# ---------- DataLoaders ----------\n",
    "train_loader = DataLoader(\n",
    "    RatingsDataset(train_u, train_m, train_r, train_genres),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "if len(val_u) > 0:\n",
    "    val_loader = DataLoader(\n",
    "        RatingsDataset(val_u, val_m, val_r, val_genres),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        pin_memory=PIN_MEMORY,\n",
    "        num_workers=NUM_WORKERS\n",
    "    )\n",
    "else:\n",
    "    val_loader = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbdb3e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8bbdb3e1",
    "outputId": "3f4a3514-bf5a-47f5-e472-adcc53a3752e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model initialized with 25070351 parameters\n"
     ]
    }
   ],
   "source": [
    "# ---------- Model ----------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = HybridMatrixFactorization(\n",
    "    num_users,\n",
    "    num_movies,\n",
    "    N_FACTORS,\n",
    "    n_genres,\n",
    "    dropout=MODEL_DROPOUT,\n",
    "    genre_weight=GENRE_WEIGHT\n",
    ").to(device)\n",
    "model.global_bias.data = torch.tensor([train_r.mean()], device=device)\n",
    "\n",
    "print(f\"Model initialized with {sum(p.numel() for p in model.parameters())} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b28dad7",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "1b28dad7",
    "outputId": "883eeeee-6664-42ac-8067-3445465acf3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train_rmse=1.7455 | val_rmse=1.6443\n",
      "Epoch 002 | train_rmse=1.5953 | val_rmse=1.5948\n",
      "Epoch 003 | train_rmse=1.5269 | val_rmse=1.5735\n",
      "Epoch 004 | train_rmse=1.4760 | val_rmse=1.5667\n",
      "Epoch 005 | train_rmse=1.4371 | val_rmse=1.5675\n",
      "Best validation RMSE: 1.5667\n"
     ]
    }
   ],
   "source": [
    "# ---------- Train ----------\n",
    "best_val = train_fn(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    epochs=EPOCHS,\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    clip_grad=CLIP_GRAD_NORM\n",
    ")\n",
    "print(f\"Best validation RMSE: {best_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c13505",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "57c13505",
    "outputId": "e23eda51-0e03-4ba7-e69a-b8e92b32d2cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 61191 movie embeddings.\n"
     ]
    }
   ],
   "source": [
    "# ---------- Export Movie Embeddings ----------\n",
    "genre_tensor = torch.tensor(genre_matrix, dtype=torch.float32).to(device)\n",
    "movie_embeddings = model.movie_factors.weight + model.genre_weight * model.genre_layer(genre_tensor)\n",
    "movie_embeddings = movie_embeddings.detach().cpu().numpy()\n",
    "movie_embeddings = np.nan_to_num(movie_embeddings)\n",
    "\n",
    "idx2movie = {v: k for k, v in movie2idx.items()}\n",
    "df_movie_embeddings = pd.DataFrame({\n",
    "    \"movie_id\": [int(idx2movie[i]) for i in range(len(idx2movie))],\n",
    "    \"embedding\": movie_embeddings.tolist()\n",
    "})\n",
    "\n",
    "# Upsert new embeddings in chunks (avoids delete timeout)\n",
    "records = df_movie_embeddings.to_dict(orient=\"records\")\n",
    "for i in range(0, len(records), CHUNK_SIZE):\n",
    "    supabase.table(MOVIE_EMBEDDINGS_TABLE).upsert(records[i:i+CHUNK_SIZE], on_conflict='movie_id').execute()\n",
    "\n",
    "print(f\"Saved {len(records)} movie embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4945615f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4945615f",
    "outputId": "8ca8de24-bffe-4513-b448-dc3604ad7550"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 3 trained user embeddings.\n",
      "Fetching user genre preferences...\n",
      "Computed 2 fold-in user embeddings from preferences.\n",
      "Successfully saved 5 TOTAL user embeddings.\n"
     ]
    }
   ],
   "source": [
    "# ---------- Export User Embeddings ----------\n",
    "user_embeddings_weights = model.user_factors.weight.detach().cpu().numpy()\n",
    "user_embeddings_weights = np.nan_to_num(user_embeddings_weights)\n",
    "\n",
    "# Supabase users only (handle empty df_supabase case)\n",
    "if not df_supabase.empty and \"userId\" in df_supabase.columns:\n",
    "    supabase_user_ids = set(df_supabase[\"userId\"].unique())\n",
    "else:\n",
    "    supabase_user_ids = set()\n",
    "\n",
    "idx2user = {v: k for k, v in user2idx.items()}\n",
    "\n",
    "# 1. Collect TRAINED user embeddings\n",
    "trained_records = []\n",
    "for i, emb in enumerate(user_embeddings_weights):\n",
    "    if idx2user[i] in supabase_user_ids:\n",
    "        trained_records.append({\"user_id\": idx2user[i], \"embedding\": emb.tolist()})\n",
    "\n",
    "print(f\"Prepared {len(trained_records)} trained user embeddings.\")\n",
    "\n",
    "# 2. Handle 'Fold-in' Users (Cold Start)\n",
    "# Fetch users who have preferences in user_genre_preferences table\n",
    "print(\"Fetching user genre preferences...\")\n",
    "try:\n",
    "    resp = supabase.table(\"user_genre_preferences\").select(\"user_id, genre\").execute()\n",
    "    df_prefs = pd.DataFrame(resp.data)\n",
    "except Exception as e:\n",
    "    print(f\"Skipping fold-in users (error fetching preferences): {e}\")\n",
    "    df_prefs = pd.DataFrame()\n",
    "\n",
    "fold_in_records = []\n",
    "if not df_prefs.empty:\n",
    "    W_genre = model.genre_layer.weight.detach().cpu().numpy() # (n_factors, n_genres)\n",
    "    b_genre = model.genre_layer.bias.detach().cpu().numpy()   # (n_factors,)\n",
    "\n",
    "    valid_genres = set(genre_cols)\n",
    "    trained_user_ids = set(r['user_id'] for r in trained_records)\n",
    "\n",
    "    # Group by user_id\n",
    "    grouped = df_prefs.groupby(\"user_id\")['genre'].apply(list)\n",
    "\n",
    "    for uid, genres in grouped.items():\n",
    "        if uid in trained_user_ids:\n",
    "            continue # Already exported via training\n",
    "\n",
    "        indices = []\n",
    "        for g in genres:\n",
    "            # Map \"Action\" -> \"gAction\" based on GENRE_COLUMN_PREFIX\n",
    "            target_col = GENRE_COLUMN_PREFIX + g\n",
    "            if target_col in genre_cols:\n",
    "                 indices.append(genre_cols.index(target_col))\n",
    "            # Fallback for exact match\n",
    "            elif g in genre_cols:\n",
    "                 indices.append(genre_cols.index(g))\n",
    "\n",
    "        if indices:\n",
    "            vectors = W_genre[:, indices]\n",
    "            avg_vector = vectors.mean(axis=1) + b_genre\n",
    "            fold_in_records.append({\n",
    "                \"user_id\": uid,\n",
    "                \"embedding\": avg_vector.tolist()\n",
    "            })\n",
    "\n",
    "print(f\"Computed {len(fold_in_records)} fold-in user embeddings from preferences.\")\n",
    "\n",
    "# 3. Combine and Upsert\n",
    "all_records = trained_records + fold_in_records\n",
    "\n",
    "if all_records:\n",
    "    # Safe to upsert\n",
    "    for i in range(0, len(all_records), CHUNK_SIZE):\n",
    "        chunk = all_records[i:i+CHUNK_SIZE]\n",
    "        supabase.table(USER_EMBEDDINGS_TABLE).upsert(chunk, on_conflict='user_id').execute()\n",
    "\n",
    "    print(f\"Successfully saved {len(all_records)} TOTAL user embeddings.\")\n",
    "else:\n",
    "    print(\"No user embeddings to export.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92a30ba2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92a30ba2",
    "outputId": "814e3fdd-1f58-4466-b8c6-5ed34257567d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre layer weight shape: (64, 19)\n",
      "Genre layer bias shape: (64,)\n",
      "Genre layer 'hybrid_mf_v1' saved to genre_layers.\n",
      "All embeddings saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# ----------- Export genre_layer -------------\n",
    "W = model.genre_layer.weight.detach().cpu().numpy()  # shape: (n_factors, n_genres)\n",
    "b = model.genre_layer.bias.detach().cpu().numpy()    # shape: (n_factors,)\n",
    "\n",
    "print(f\"Genre layer weight shape: {W.shape}\")\n",
    "print(f\"Genre layer bias shape: {b.shape}\")\n",
    "\n",
    "# Prepare the genre layer record for Supabase\n",
    "genre_layer_record = {\n",
    "    \"name\": GENRE_LAYER_NAME,\n",
    "    \"genre_names\": genre_cols,  # List of genre column names\n",
    "    \"weight\": W.tolist(),       # Convert to nested list for JSONB\n",
    "    \"bias\": b.tolist()          # Convert to list for JSONB\n",
    "}\n",
    "\n",
    "# Delete existing record with same name (upsert behavior)\n",
    "supabase.table(GENRE_LAYERS_TABLE).delete().eq(\"name\", GENRE_LAYER_NAME).execute()\n",
    "\n",
    "# Insert the new genre layer\n",
    "supabase.table(GENRE_LAYERS_TABLE).insert(genre_layer_record).execute()\n",
    "\n",
    "print(f\"Genre layer '{GENRE_LAYER_NAME}' saved to {GENRE_LAYERS_TABLE}.\")\n",
    "print(\"All embeddings saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
