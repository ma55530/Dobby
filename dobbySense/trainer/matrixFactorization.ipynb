{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a625e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Install Dependencies (run this cell first in Colab) ---\n",
    "!pip install -q supabase gcsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05524b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION - All hyperparameters and hardcoded variables\n",
    "# ============================================================\n",
    "\n",
    "# --- Data Paths ---\n",
    "RATINGS_PATH = \"gs://kanta7/ratings.csv\"\n",
    "MOVIES_PATH = \"gs://kanta7/movies.csv\"\n",
    "\n",
    "# --- Supabase Configuration ---\n",
    "SUPABASE_URL = \"https://mgagzgashuexrnkoqkzy.supabase.co\"\n",
    "SUPABASE_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im1nYWd6Z2FzaHVleHJua29xa3p5Iiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1OTkwOTM5NSwiZXhwIjoyMDc1NDg1Mzk1fQ.0klXZZv3b31usiUKTQxyfXsFPLr5TLPDikUY6s3wrPo\"\n",
    "\n",
    "# --- Supabase Table Names ---\n",
    "RATINGS_TABLE = \"movie_ratings\"\n",
    "MOVIE_EMBEDDINGS_TABLE = \"movie_embeddings\"\n",
    "USER_EMBEDDINGS_TABLE = \"user_embeddings\"\n",
    "GENRE_LAYERS_TABLE = \"genre_layers\"\n",
    "\n",
    "# --- Data Processing ---\n",
    "TEST_SIZE = 0.1\n",
    "RANDOM_STATE = 42\n",
    "GENRE_COLUMN_PREFIX = \"g\"\n",
    "\n",
    "# --- DataLoader Settings ---\n",
    "BATCH_SIZE = 2048\n",
    "NUM_WORKERS = 2\n",
    "PIN_MEMORY = True\n",
    "\n",
    "# --- Model Hyperparameters ---\n",
    "N_FACTORS = 64\n",
    "MODEL_DROPOUT = 0.1\n",
    "EMBEDDING_INIT_STD = 0.01\n",
    "\n",
    "# --- Training Hyperparameters ---\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-6\n",
    "CLIP_GRAD_NORM = None  # Set to a float value to enable gradient clipping\n",
    "\n",
    "# --- Export Settings ---\n",
    "CHUNK_SIZE = 500  # For batch inserts to Supabase\n",
    "GENRE_LAYER_NAME = \"hybrid_mf_v1\"  # Name for the genre layer export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a90394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from supabase import create_client, Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0e5797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Google Cloud Authentication (required for GCS bucket access) ---\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0300e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Dataset ----------\n",
    "class RatingsDataset(Dataset):\n",
    "    def __init__(self, user_idx, movie_idx, ratings, genre_matrix):\n",
    "        assert len(user_idx) == len(movie_idx) == len(ratings)\n",
    "        self.users = torch.tensor(user_idx, dtype=torch.long)\n",
    "        self.movies = torch.tensor(movie_idx, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(ratings, dtype=torch.float32)\n",
    "        self.genres = torch.tensor(genre_matrix, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.movies[idx], self.ratings[idx], self.genres[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d66e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Utilities ----------\n",
    "def build_id_maps(df: pd.DataFrame, user_col='userId', movie_col='movieId'):\n",
    "    unique_users = df[user_col].unique()\n",
    "    unique_movies = df[movie_col].unique()\n",
    "    user2idx = {u: i for i, u in enumerate(np.sort(unique_users))}\n",
    "    movie2idx = {m: j for j, m in enumerate(np.sort(unique_movies))}\n",
    "    user_idx = df[user_col].map(user2idx).to_numpy()\n",
    "    movie_idx = df[movie_col].map(movie2idx).to_numpy()\n",
    "    ratings = df['rating'].to_numpy(dtype=np.float32)\n",
    "    return user2idx, movie2idx, user_idx, movie_idx, ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5def99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Model ----------\n",
    "class HybridMatrixFactorization(nn.Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors, n_genres, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.user_factors = nn.Embedding(n_users, n_factors)\n",
    "        self.movie_factors = nn.Embedding(n_movies, n_factors)\n",
    "        self.genre_layer = nn.Linear(n_genres, n_factors)\n",
    "        self.user_bias = nn.Embedding(n_users, 1)\n",
    "        self.movie_bias = nn.Embedding(n_movies, 1)\n",
    "        self.global_bias = nn.Parameter(torch.tensor([0.0]))\n",
    "        self.dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()\n",
    "\n",
    "        nn.init.normal_(self.user_factors.weight, std=EMBEDDING_INIT_STD)\n",
    "        nn.init.normal_(self.movie_factors.weight, std=EMBEDDING_INIT_STD)\n",
    "        nn.init.constant_(self.user_bias.weight, 0.0)\n",
    "        nn.init.constant_(self.movie_bias.weight, 0.0)\n",
    "\n",
    "    def forward(self, user, movie, genre_vec):\n",
    "        pu = self.user_factors(user)\n",
    "        qi = self.movie_factors(movie)\n",
    "        genre_emb = self.genre_layer(genre_vec)\n",
    "        qi = qi + genre_emb\n",
    "        pu = self.dropout(pu)\n",
    "        qi = self.dropout(qi)\n",
    "        dot = (pu * qi).sum(dim=1)\n",
    "        b_u = self.user_bias(user).squeeze(1)\n",
    "        b_i = self.movie_bias(movie).squeeze(1)\n",
    "        return dot + b_u + b_i + self.global_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c440c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Training / Evaluation ----------\n",
    "def rmse(preds, targets):\n",
    "    return math.sqrt(((preds - targets) ** 2).mean().item())\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    ys, y_preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for u, m, r, g in dataloader:\n",
    "            u, m, r, g = u.to(device), m.to(device), r.to(device), g.to(device)\n",
    "            p = model(u, m, g)\n",
    "            ys.append(r.cpu())\n",
    "            y_preds.append(p.cpu())\n",
    "    y = torch.cat(ys)\n",
    "    yp = torch.cat(y_preds)\n",
    "    return rmse(yp, y)\n",
    "\n",
    "def train_fn(model, train_loader, val_loader, device,\n",
    "             epochs=EPOCHS, lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY, clip_grad=CLIP_GRAD_NORM):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss()\n",
    "    best_val = float('inf')\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss, cnt = 0.0, 0\n",
    "        for u, m, r, g in train_loader:\n",
    "            u, m, r, g = u.to(device), m.to(device), r.to(device), g.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(u, m, g)\n",
    "            loss = criterion(preds, r)\n",
    "            loss.backward()\n",
    "            if clip_grad:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * r.size(0)\n",
    "            cnt += r.size(0)\n",
    "\n",
    "        train_rmse = math.sqrt(total_loss / cnt)\n",
    "        val_rmse = evaluate(model, val_loader, device)\n",
    "        print(f\"Epoch {epoch:03d} | train_rmse={train_rmse:.4f} | val_rmse={val_rmse:.4f}\")\n",
    "\n",
    "        if val_rmse < best_val:\n",
    "            best_val = val_rmse\n",
    "\n",
    "    return best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b648648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Load Data ----------\n",
    "df = pd.read_csv(RATINGS_PATH)\n",
    "movies_df = pd.read_csv(MOVIES_PATH)\n",
    "\n",
    "df[\"userId\"] = df[\"userId\"].astype(str)\n",
    "movies_df[\"movieId\"] = movies_df[\"movieId\"].astype(int)\n",
    "genre_cols = [c for c in movies_df.columns if c.startswith(GENRE_COLUMN_PREFIX)]\n",
    "n_genres = len(genre_cols)\n",
    "\n",
    "print(f\"Loaded {len(df)} ratings and {len(movies_df)} movies with {n_genres} genres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd5c73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Supabase Connection ---\n",
    "supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
    "\n",
    "# Fetch extra ratings from Supabase\n",
    "response = supabase.table(RATINGS_TABLE).select(\"user_id, movie_id, rating\").execute()\n",
    "df_supabase = pd.DataFrame(response.data).rename(columns={\n",
    "    \"user_id\": \"userId\", \"movie_id\": \"movieId\", \"rating\": \"rating\"\n",
    "})\n",
    "df = pd.concat([df, df_supabase], ignore_index=True)\n",
    "\n",
    "print(f\"After merging Supabase data: {len(df)} total ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee394e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Prepare Data ----------\n",
    "train_df, val_df = train_test_split(df, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "user2idx, movie2idx, train_u, train_m, train_r = build_id_maps(train_df)\n",
    "val_df = val_df[val_df['userId'].isin(user2idx) & val_df['movieId'].isin(movie2idx)]\n",
    "val_u = val_df['userId'].map(user2idx).to_numpy()\n",
    "val_m = val_df['movieId'].map(movie2idx).to_numpy()\n",
    "val_r = val_df['rating'].to_numpy(dtype=np.float32)\n",
    "\n",
    "# Build genre matrix aligned with movie indices\n",
    "genre_matrix = np.zeros((len(movie2idx), n_genres), dtype=np.float32)\n",
    "for _, row in movies_df.iterrows():\n",
    "    mid = row['movieId']\n",
    "    if mid in movie2idx:\n",
    "        genre_matrix[movie2idx[mid]] = row[genre_cols].values.astype(np.float32)\n",
    "\n",
    "train_genres = genre_matrix[train_m]\n",
    "val_genres = genre_matrix[val_m]\n",
    "\n",
    "num_users, num_movies = len(user2idx), len(movie2idx)\n",
    "print(f\"Training {num_users} users, {num_movies} movies, {n_genres} genres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5583905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- DataLoaders ----------\n",
    "train_loader = DataLoader(\n",
    "    RatingsDataset(train_u, train_m, train_r, train_genres),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    RatingsDataset(val_u, val_m, val_r, val_genres),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    num_workers=NUM_WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbdb3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Model ----------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = HybridMatrixFactorization(\n",
    "    num_users,\n",
    "    num_movies,\n",
    "    N_FACTORS,\n",
    "    n_genres,\n",
    "    dropout=MODEL_DROPOUT\n",
    ").to(device)\n",
    "model.global_bias.data = torch.tensor([train_r.mean()], device=device)\n",
    "\n",
    "print(f\"Model initialized with {sum(p.numel() for p in model.parameters())} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b28dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Train ----------\n",
    "best_val = train_fn(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    epochs=EPOCHS,\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    clip_grad=CLIP_GRAD_NORM\n",
    ")\n",
    "print(f\"Best validation RMSE: {best_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c13505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Export Movie Embeddings ----------\n",
    "genre_tensor = torch.tensor(genre_matrix, dtype=torch.float32).to(device)\n",
    "movie_embeddings = model.movie_factors.weight + model.genre_layer(genre_tensor)\n",
    "movie_embeddings = movie_embeddings.detach().cpu().numpy()\n",
    "movie_embeddings = np.nan_to_num(movie_embeddings)\n",
    "\n",
    "idx2movie = {v: k for k, v in movie2idx.items()}\n",
    "df_movie_embeddings = pd.DataFrame({\n",
    "    \"movie_id\": [int(idx2movie[i]) for i in range(len(idx2movie))],\n",
    "    \"embedding\": movie_embeddings.tolist()\n",
    "})\n",
    "\n",
    "# Delete old embeddings\n",
    "supabase.table(MOVIE_EMBEDDINGS_TABLE).delete().neq(\"movie_id\", -1).execute()\n",
    "\n",
    "# Insert new embeddings in chunks\n",
    "records = df_movie_embeddings.to_dict(orient=\"records\")\n",
    "for i in range(0, len(records), CHUNK_SIZE):\n",
    "    supabase.table(MOVIE_EMBEDDINGS_TABLE).insert(records[i:i+CHUNK_SIZE]).execute()\n",
    "\n",
    "print(f\"Saved {len(records)} movie embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4945615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Export User Embeddings ----------\n",
    "user_embeddings = model.user_factors.weight.detach().cpu().numpy()\n",
    "user_embeddings = np.nan_to_num(user_embeddings)\n",
    "\n",
    "# Supabase users only (handle empty df_supabase case)\n",
    "if not df_supabase.empty and \"userId\" in df_supabase.columns:\n",
    "    supabase_user_ids = set(df_supabase[\"userId\"].unique())\n",
    "else:\n",
    "    supabase_user_ids = set()\n",
    "\n",
    "idx2user = {v: k for k, v in user2idx.items()}\n",
    "\n",
    "# Create user embedding records only for Supabase users\n",
    "user_records = [\n",
    "    {\"user_id\": idx2user[i], \"embedding\": emb.tolist()}\n",
    "    for i, emb in enumerate(user_embeddings)\n",
    "    if idx2user[i] in supabase_user_ids\n",
    "]\n",
    "\n",
    "if user_records:\n",
    "    # Delete existing user embeddings\n",
    "    supabase.table(USER_EMBEDDINGS_TABLE).delete().not_.is_(\"user_id\", \"null\").execute()\n",
    "\n",
    "    # Insert new user embeddings in chunks\n",
    "    for i in range(0, len(user_records), CHUNK_SIZE):\n",
    "        supabase.table(USER_EMBEDDINGS_TABLE).insert(user_records[i:i+CHUNK_SIZE]).execute()\n",
    "\n",
    "    print(f\"Saved {len(user_records)} user embeddings.\")\n",
    "else:\n",
    "    print(\"No Supabase user embeddings to export (no ratings from Supabase users yet).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a30ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Export genre_layer -------------\n",
    "W = model.genre_layer.weight.detach().cpu().numpy()  # shape: (n_factors, n_genres)\n",
    "b = model.genre_layer.bias.detach().cpu().numpy()    # shape: (n_factors,)\n",
    "\n",
    "print(f\"Genre layer weight shape: {W.shape}\")\n",
    "print(f\"Genre layer bias shape: {b.shape}\")\n",
    "\n",
    "# Prepare the genre layer record for Supabase\n",
    "genre_layer_record = {\n",
    "    \"name\": GENRE_LAYER_NAME,\n",
    "    \"genre_names\": genre_cols,  # List of genre column names\n",
    "    \"weight\": W.tolist(),       # Convert to nested list for JSONB\n",
    "    \"bias\": b.tolist()          # Convert to list for JSONB\n",
    "}\n",
    "\n",
    "# Delete existing record with same name (upsert behavior)\n",
    "supabase.table(GENRE_LAYERS_TABLE).delete().eq(\"name\", GENRE_LAYER_NAME).execute()\n",
    "\n",
    "# Insert the new genre layer\n",
    "supabase.table(GENRE_LAYERS_TABLE).insert(genre_layer_record).execute()\n",
    "\n",
    "print(f\"Genre layer '{GENRE_LAYER_NAME}' saved to {GENRE_LAYERS_TABLE}.\")\n",
    "print(\"All embeddings saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
